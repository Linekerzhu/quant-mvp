# Phase C å·¥ç¨‹å®æ–½æŒ‡å— (Implementation Guide)

> **å®šä½**ï¼šæœ¬æ–‡æ¡£æ˜¯ `plan.md` Phase C æ®µçš„é€è¡Œå®æ–½æ‰‹å†Œï¼Œä¾›å·¥ç¨‹ Agent ç›´æ¥æ‰§è¡Œã€‚
> æ¶æ„å†³ç­–ä¸éªŒæ”¶æ ‡å‡†ä»¥ `plan.md v4.2` ä¸ºå‡†ï¼Œæœ¬æ–‡æ¡£åªè´Ÿè´£ HOWï¼ˆæ€ä¹ˆå†™ä»£ç ï¼‰ã€‚

## ä½ éœ€è¦çŸ¥é“çš„ä¸€åˆ‡ï¼ˆ2 åˆ†é’Ÿç‰ˆï¼‰

### é¡¹ç›®æ˜¯ä»€ä¹ˆ
ç¾è‚¡æ—¥é¢‘é‡åŒ–äº¤æ˜“ç³»ç»Ÿã€‚ç”¨ LightGBM é¢„æµ‹äº¤æ˜“ä¿¡å·çš„ç›ˆäºæ¦‚ç‡ï¼Œå†³å®šä»“ä½å¤§å°ã€‚

### ç°åœ¨åˆ°å“ªäº†
- **Phase Aï¼ˆæ•°æ®ç®¡é“ï¼‰**: âœ… å®Œæˆã€‚yfinance æ‹‰æ•°æ® â†’ æ ¡éªŒ â†’ ç‰¹å¾å·¥ç¨‹ â†’ 20 ä¸ªç‰¹å¾ã€‚
- **Phase Bï¼ˆæ ‡ç­¾ç³»ç»Ÿï¼‰**: âœ… å®Œæˆã€‚Triple Barrier æ‰“æ ‡ â†’ æ ·æœ¬æƒé‡ â†’ sklearn-ready æ•°æ®ã€‚
- **Phase Cï¼ˆæ¨¡å‹è®­ç»ƒï¼‰**: ğŸ”´ ç°åœ¨å¼€å§‹ã€‚æœ¬æ–‡æ¡£å°±æ˜¯ Phase C çš„æ–½å·¥å›¾çº¸ã€‚

### æ ¸å¿ƒæ¶æ„çº¦æŸï¼ˆè¿åå³ä¸€ç¥¨å¦å†³ï¼‰
è¿™äº›æ˜¯å¤–éƒ¨å®¡è®¡å®˜ç­¾ç½²çš„å¼ºåˆ¶å¥‘çº¦ï¼Œä¸æ˜¯å»ºè®®ï¼Œæ˜¯çº¢çº¿ï¼š

1. **LightGBM ä¸èƒ½ç›´æ¥é¢„æµ‹æ¶¨è·Œ** â†’ å¿…é¡»ç”¨ Meta-Labeling æ¶æ„
2. **max_depth â‰¤ 3, num_leaves â‰¤ 7** â†’ å·²é”æ­»åœ¨ training.yaml
3. **å¿…é¡»ç”¨åˆ†æ•°é˜¶å·®åˆ†ï¼ˆFracDiffï¼‰** â†’ ä¸èƒ½å–‚ç»å¯¹ä»·æ ¼ï¼Œä¹Ÿä¸èƒ½åªç”¨ä¸€é˜¶å·®åˆ†
4. **å¿…é¡»æ‰‹å†™ CPCV Purge+Embargo** â†’ ä¸èƒ½ç”¨æ ‡å‡† KFoldï¼Œä¸èƒ½ç”¨ç¬¬ä¸‰æ–¹åº“ç³Šå¼„
5. **å›æµ‹æŠ¥å‘Šå¿…é¡»æ‰£å‡** â†’ CAGR -3%, MDD +10%ï¼ˆæ•°æ®æŠ€æœ¯å€ºæƒ©ç½šï¼‰

### æ–½å·¥é¡ºåºï¼ˆä¸¥ç¦é¢ å€’ï¼‰

```
Step 1: Base Modelï¼ˆç‚®ç°ä¿¡å·æºï¼‰
   â†“
Step 2: CPCV éš”ç¦»å™¨ï¼ˆæ‰‹æ’• PurgedKFoldï¼‰
   â†“
Step 3: FracDiff ç‰¹å¾é‡æ„
   â†“
Step 4: Meta-MVP é—­ç¯
```

---

## å‰ç½®ä»»åŠ¡ï¼šPush OR5 Hotfix

å·¥ä½œç›®å½•ä¸­æœ‰æœªæäº¤çš„ OR5 å®¡è®¡çƒ­ä¿®å¤ã€‚**åœ¨å¼€å§‹ Phase C ä¹‹å‰å¿…é¡»å…ˆæäº¤ã€‚**

```bash
cd /path/to/quant-mvp
git add -A
git commit -m "hotfix(OR5): Maximum Pessimism Principle + LGBåKaggleç¡¬åŒ– + PhaseCå¥‘çº¦

- triple_barrier: Gap execution + Collision detection + æ­¢æŸä¼˜å…ˆ
- training.yaml: max_depth=3, num_leaves=7, min_data_in_leaf=200
- æ–°å¢ test_smoke_or5.py (29 tests) + OR5_CONTRACT.md
- 112/112 tests passing"
git push origin main
```

éªŒè¯ï¼š`git log --oneline -1` åº”æ˜¾ç¤º OR5 hotfix commitã€‚

---

## Step 1: Base Modelï¼ˆç‚®ç°ä¿¡å·æºï¼‰

### ç›®æ ‡
å†™ä¸€ä¸ªæç®€è§„åˆ™ç­–ç•¥ï¼Œä¸ºæ¯ä¸ªäº¤æ˜“æ—¥çš„æ¯åªè‚¡ç¥¨ç”Ÿæˆæ–¹å‘ä¿¡å· `side âˆˆ {+1, -1, 0}`ã€‚
è¿™ä¸ªç­–ç•¥**ä¸éœ€è¦èµšé’±**â€”â€”å®ƒåªæ˜¯ Meta Model çš„è¾“å…¥ä¿¡å·æºã€‚

### æ–°å»ºæ–‡ä»¶

**`src/signals/base_models.py`**

```
æ¥å£å®šä¹‰:

class BaseModelSMA:
    """åŒå‡çº¿é‡‘å‰/æ­»å‰ä¿¡å·"""
    
    def __init__(self, fast_window=20, slow_window=60):
        self.fast_window = fast_window
        self.slow_window = slow_window
    
    def generate_signals(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        è¾“å…¥: å« symbol, date, adj_close çš„ DataFrame
        è¾“å‡º: åŒ DataFrameï¼Œæ–°å¢ 'side' åˆ—
              side = +1: å¿«å‡çº¿ > æ…¢å‡çº¿ï¼ˆçœ‹å¤šï¼‰
              side = -1: å¿«å‡çº¿ < æ…¢å‡çº¿ï¼ˆçœ‹ç©ºï¼‰
              side =  0: æ•°æ®ä¸è¶³ï¼ˆå†·å¯åŠ¨æœŸï¼‰
        
        å…³é”®çº¦æŸ:
        - å‡çº¿å¿…é¡»ç”¨ .shift(1)ï¼Œå³ T æ—¥ä¿¡å·åªèƒ½ç”¨ T-1 åŠä¹‹å‰çš„æ•°æ®
        - ä¸èƒ½å·çœ‹ T æ—¥çš„æ”¶ç›˜ä»·æ¥å†³å®š T æ—¥çš„ä¿¡å·
        """
```

### éœ€è¦å®ç°çš„ Base Modelï¼ˆè‡³å°‘ 2 ä¸ªï¼Œåç»­å¯æ‰©å±•ï¼‰

| æ¨¡å‹ | é€»è¾‘ | side=+1 æ¡ä»¶ | side=-1 æ¡ä»¶ |
|------|------|-------------|-------------|
| SMA Cross | 20/60 åŒå‡çº¿ | SMA20 > SMA60 | SMA20 < SMA60 |
| Momentum | 20 æ—¥åŠ¨é‡ | returns_20d > 0 | returns_20d < 0 |

### æ ¸å¿ƒé˜²æ³„æ¼æ£€æŸ¥
```python
# âŒ é”™è¯¯ï¼šT æ—¥ä¿¡å·ç”¨äº† T æ—¥ä»·æ ¼
sma_fast = df['adj_close'].rolling(20).mean()
df['side'] = np.where(sma_fast > sma_slow, 1, -1)

# âœ… æ­£ç¡®ï¼šT æ—¥ä¿¡å·åªèƒ½ç”¨ T-1 åŠä¹‹å‰
sma_fast = df['adj_close'].shift(1).rolling(20).mean()
df['side'] = np.where(sma_fast > sma_slow, 1, -1)
```

### ä¸ Triple Barrier çš„å¯¹æ¥

Base Model äº§ç”Ÿ side åï¼Œåªæœ‰ `side != 0` çš„æ—¥æœŸæ‰è§¦å‘ Triple Barrier æ‰“æ ‡ã€‚
åœ¨ `triple_barrier.py` çš„ `_is_valid_event` ä¸­å¢åŠ ä¸€ä¸ªæ£€æŸ¥ï¼š

```python
# å¦‚æœ df æœ‰ 'side' åˆ—ï¼Œåªåœ¨ side != 0 æ—¶è§¦å‘äº‹ä»¶
if 'side' in symbol_df.columns:
    if symbol_df.loc[idx, 'side'] == 0:
        return False, 'no_signal'
```

æ‰“æ ‡åçš„ label å«ä¹‰å˜åŒ–ï¼š
- æ—§ï¼šlabel=1 è¡¨ç¤º"ä»·æ ¼ä¸Šæ¶¨åˆ°æ­¢ç›ˆ"
- æ–°ï¼ˆMeta-Labelingï¼‰ï¼šlabel=1 è¡¨ç¤º"**Base Model è¿™æ¬¡ä¿¡å·èµšäº†é’±**"ï¼Œlabel=0 è¡¨ç¤º"äºäº†"

### æµ‹è¯•æ ‡å‡†
```
tests/test_base_models.py:
  - test_sma_signal_no_lookahead: éªŒè¯ shift(1)
  - test_signal_values: side âˆˆ {-1, 0, +1}
  - test_cold_start: å‰ slow_window å¤© side=0
  - test_signal_with_pipeline: base_model â†’ triple_barrier èƒ½è·‘é€š
```

### äº¤ä»˜ç‰©
- `src/signals/base_models.py`ï¼ˆ2 ä¸ª Base Modelï¼‰
- `tests/test_base_models.py`ï¼ˆ4+ ä¸ªæµ‹è¯•ï¼‰
- å…¨é‡æµ‹è¯•é€šè¿‡

---

## Step 2: CPCV éš”ç¦»å™¨ï¼ˆæœ€ç¡¬çš„éª¨å¤´ï¼‰

### ç›®æ ‡
æ‰‹å†™ `CombinatorialPurgedKFold`ï¼Œç¡®ä¿è®­ç»ƒé›†å’ŒéªŒè¯é›†ä¹‹é—´é›¶ä¿¡æ¯æ³„æ¼ã€‚

### ä¸ºä»€ä¹ˆä¸èƒ½ç”¨æ ‡å‡† KFold
é‡‘èæ•°æ®æœ‰æ—¶é—´ä¾èµ–æ€§ã€‚æ ‡å‡† KFold ä¼šæŠŠ 2024 å¹´ 3 æœˆçš„æ•°æ®æ”¾è¿›è®­ç»ƒé›†ï¼Œ
ç„¶åç”¨ 2024 å¹´ 2 æœˆçš„æ•°æ®åšéªŒè¯â€”â€”æ¨¡å‹å·çœ‹äº†æœªæ¥ã€‚

### æ–°å»ºæ–‡ä»¶

**`src/models/purged_kfold.py`**

```
æ ¸å¿ƒæ¥å£:

class CombinatorialPurgedKFold:
    """
    AFML Ch7: Combinatorial Purged K-Fold Cross-Validation
    
    å‚æ•° (ä» config/training.yaml è¯»å–):
        n_splits: 6          # å°†æ—¶é—´çº¿åˆ‡æˆ 6 æ®µ
        n_test_splits: 2     # æ¯æ¬¡é€‰ 2 æ®µåšæµ‹è¯•
        purge_window: 10     # å¤© (= max_holding_days)
        embargo_window: 40   # å¤©
    
    ç»„åˆæ•°: C(6,2) = 15 æ¡ CPCV path
    """
    
    def __init__(self, config_path="config/training.yaml"):
        ...
    
    def split(self, df: pd.DataFrame) -> Iterator[Tuple[np.array, np.array]]:
        """
        è¾“å…¥: å« date, label_exit_date çš„ DataFrameï¼ˆå¿…é¡»å·²ç»è¿‡ triple_barrier æ‰“æ ‡ï¼‰
        
        äº§å‡º: (train_indices, test_indices) çš„è¿­ä»£å™¨ï¼Œå…± 15 ç»„
        
        æ¯ç»„çš„éš”ç¦»è§„åˆ™:
        1. æ—¶é—´çº¿åˆ‡æˆ 6 æ®µï¼Œé€‰ 2 æ®µåš Test
        2. Purge: ä» Train ä¸­åˆ é™¤æ‰€æœ‰æ»¡è¶³ä»¥ä¸‹æ¡ä»¶çš„æ ·æœ¬:
           æ ·æœ¬çš„ [entry_date, label_exit_date] åŒºé—´
           ä¸ Test é›†çš„ [min_date - max_lookback, max_date] æœ‰ä»»ä½•ä¸€å¤©äº¤é›†
        3. Embargo: Test é›† max_date ä¹‹å 40 å¤©å†…çš„ Train æ ·æœ¬ï¼Œå…¨éƒ¨åˆ é™¤
        
        å…³é”®:
        - ç”¨ label_exit_dateï¼ˆç²¾ç¡®çš„é€€å‡ºæ—¥æœŸï¼‰ï¼Œä¸æ˜¯ç”¨ max_holding_days è¿‘ä¼¼
        - æ¯ä¸ª path çš„æœ‰æ•ˆè®­ç»ƒå¤©æ•°å¿…é¡» â‰¥ 200 å¤©ï¼Œå¦åˆ™æ ‡è®°ä¸º invalid
        """
    
    def get_n_paths(self) -> int:
        """è¿”å› 15"""
        return comb(self.n_splits, self.n_test_splits)
```

### Purge çš„ç²¾ç¡®ç®—æ³•ï¼ˆé€æ ·æœ¬ï¼‰

```python
def _purge(self, train_indices, test_df, full_df):
    """
    å¯¹ train_indices ä¸­çš„æ¯ä¸ªæ ·æœ¬:
    
    1. å–è¯¥æ ·æœ¬çš„ entry_date å’Œ exit_date = label_exit_date
    2. å– test_df çš„æ—¶é—´èŒƒå›´: test_start = test_df['date'].min()
                              test_end = test_df['date'].max()
    3. è®¡ç®— test çš„ç‰¹å¾å›æº¯è¾¹ç•Œ: test_lookback_start = test_start - max_lookback_days
    
    4. å¦‚æœæ ·æœ¬åŒºé—´ [entry_date, exit_date] ä¸ 
       [test_lookback_start, test_end] æœ‰ä»»ä½•äº¤é›†:
       â†’ ä» train ä¸­åˆ é™¤è¯¥æ ·æœ¬
    
    äº¤é›†åˆ¤å®š: entry_date <= test_end AND exit_date >= test_lookback_start
    """
```

### Embargo çš„ç²¾ç¡®ç®—æ³•

```python
def _embargo(self, train_indices, test_end_date, full_df):
    """
    ä» train_indices ä¸­åˆ é™¤æ‰€æœ‰:
    full_df.loc[idx, 'date'] åœ¨ (test_end_date, test_end_date + embargo_window] å†…çš„æ ·æœ¬
    """
```

### âš ï¸ Embargo ä¸ Feature Lookback çš„ 20 å¤©ç¼ºå£

å½“å‰ `embargo_window=40 < feature_lookback=60`ã€‚è¿™æ„å‘³ç€ test ç»“æŸåç¬¬ 41-60 å¤©çš„ train æ ·æœ¬ï¼Œ
å…¶ç‰¹å¾ä¼šå›æº¯è¿›å…¥ test é›†çš„æœ€åå‡ å¤©ã€‚

**é—®é¢˜**ï¼š
```
Test End: 2021-09-30
Embargo Window: 40 days â†’ ç¦æ­¢ train æ ·æœ¬æ—¥æœŸåœ¨ 2021-10-01 ~ 2021-11-09
Feature Lookback: 60 days â†’ æ ·æœ¬åœ¨ 2021-11-10 è®¡ç®—ç‰¹å¾æ—¶ï¼Œä¼šå›æº¯åˆ° 2021-09-11

é£é™©ï¼š2021-11-10 çš„ train æ ·æœ¬ï¼Œå…¶ 60 å¤©ç‰¹å¾çª—å£ä¸ test é›†æœ‰ 19 å¤©é‡å 
```

**åœ¨å®ç° `_embargo()` æ—¶ï¼Œå¿…é¡»é€‰æ‹©ä»¥ä¸‹æ–¹æ¡ˆä¹‹ä¸€**ï¼š

**é€‰é¡¹ Aï¼ˆç®€å•ï¼Œæ¨è MVPï¼‰**ï¼šå°† embargo å®é™…æ‰§è¡Œå€¼è®¾ä¸º `max(embargo_window, feature_lookback)=60`
- ä¼˜ç‚¹ï¼šå®ç°ç®€å•ï¼Œé›¶æ³„æ¼é£é™©
- ç¼ºç‚¹ï¼šæŸå¤±çº¦ 8% è®­ç»ƒæ•°æ®

**é€‰é¡¹ Bï¼ˆç²¾ç¡®ï¼Œä¿ç•™æ•°æ®ï¼‰**ï¼šembargo=40ï¼Œä½†å¯¹ test_end å 40-60 å¤©çš„æ ·æœ¬é¢å¤–æ£€æŸ¥
```python
# åœ¨ _embargo() ä¸­å¢åŠ åå‘ç‰¹å¾å›æº¯æ£€æŸ¥
for idx in train_indices_after_embargo:
    sample_date = full_df.loc[idx, 'date']
    feature_start = sample_date - pd.Timedelta(days=feature_lookback)
    if feature_start < test_end_date:
        # ç‰¹å¾å›æº¯ç©¿é€ test é›†ï¼Œé¢å¤– Drop
        train_indices_after_embargo.remove(idx)
```
- ä¼˜ç‚¹ï¼šä¿ç•™æ›´å¤šè®­ç»ƒæ•°æ®
- ç¼ºç‚¹ï¼šå®ç°å¤æ‚ï¼Œéœ€è¦ä¼ å…¥ feature_lookback å‚æ•°

**æ¨è**ï¼šPhase C Step 2 å¼€å·¥æ—¶é»˜è®¤ä½¿ç”¨ **é€‰é¡¹ A**ï¼ŒPhase C å®Œæˆåå¯è€ƒè™‘ä¼˜åŒ–ä¸ºé€‰é¡¹ Bã€‚

**éªŒè¯æµ‹è¯•**ï¼š
```python
# tests/test_cpcv.py å¿…é¡»åŒ…å«
test_embargo_covers_feature_lookback: 
    "éªŒè¯ test_end å feature_lookback(60) å¤©å†…æ—  train æ ·æœ¬"
```

### è‡ªè¯æ–¹æ³•ï¼ˆå®¡è®¡å®˜ä¼šæ£€æŸ¥ï¼‰

å®ç°å®Œæˆåï¼Œå¿…é¡»èƒ½è¾“å‡ºä»¥ä¸‹æ—¥å¿—ï¼š

```
CPCV Path 1/15: Test=[fold_2, fold_5]
  Test range: 2021-03-15 ~ 2021-09-30
  Train before purge: 2847 samples
  Purged: 312 samples (overlap with test label periods)
  Embargoed: 89 samples (within 40d after test end)
  Train after purge: 2446 samples (effective 487 days)
  âœ… Valid (>= 200 days)
```

### æµ‹è¯•æ ‡å‡†
```
tests/test_cpcv.py:
  - test_no_temporal_overlap: éªŒè¯ train å’Œ test æ— æ—¶é—´äº¤é›†
  - test_purge_removes_overlapping_labels: æ¨¡æ‹Ÿå·²çŸ¥é‡å ï¼Œç¡®è®¤è¢«åˆ é™¤
  - test_embargo_gap: éªŒè¯ test_end å 40 å¤©å†…æ—  train æ ·æœ¬
  - test_all_paths_valid: 15 æ¡ path æœ‰æ•ˆè®­ç»ƒå¤©æ•°å‡ â‰¥ 200
  - test_purge_uses_real_exit_date: ç¡®è®¤ä½¿ç”¨ label_exit_date è€Œé max_holding_days
```

### äº¤ä»˜ç‰©
- `src/models/purged_kfold.py`
- `tests/test_cpcv.py`ï¼ˆ5+ ä¸ªæµ‹è¯•ï¼‰
- å…¨é‡æµ‹è¯•é€šè¿‡

---

## Step 3: FracDiff ç‰¹å¾é‡æ„

### ç›®æ ‡
ç”¨åˆ†æ•°é˜¶å·®åˆ†æ›¿ä»£ç²—æš´çš„å¯¹æ•°æ”¶ç›Šç‡ï¼Œåœ¨ä¿æŒå¹³ç¨³æ€§çš„åŒæ—¶ä¿ç•™æ—¶åºè®°å¿†ã€‚

### èƒŒæ™¯çŸ¥è¯†ï¼ˆ1 åˆ†é’Ÿç‰ˆï¼‰
- ä¸€é˜¶å·®åˆ† (d=1): ç»å¯¹å¹³ç¨³ï¼Œä½†æŠ¹æ€æ‰€æœ‰è®°å¿†ï¼ˆå¦‚ returns_5dï¼‰
- é›¶é˜¶å·®åˆ† (d=0): ä¿ç•™å…¨éƒ¨è®°å¿†ï¼Œä½†éå¹³ç¨³ï¼ˆå¦‚è£¸ä»·æ ¼ï¼‰
- åˆ†æ•°é˜¶å·®åˆ† (0<d<1): æŠ˜ä¸­â€”â€”æ‰¾åˆ°æœ€å°çš„ d ä½¿å¾—åºåˆ—åˆšå¥½å¹³ç¨³

ç¾è‚¡æ—¥é¢‘æ•°æ®çš„æœ€ä¼˜ d é€šå¸¸åœ¨ **0.35 ~ 0.65** ä¹‹é—´ã€‚

### æ–°å»ºæ–‡ä»¶

**`src/features/fracdiff.py`**

```
æ ¸å¿ƒæ¥å£:

def fracdiff_fixed_window(series: pd.Series, d: float, window: int = 100) -> pd.Series:
    """
    å›ºå®šçª—å£åˆ†æ•°é˜¶å·®åˆ†ã€‚
    
    å‚æ•°:
        series: ä»·æ ¼åºåˆ—ï¼ˆå¦‚ adj_closeï¼‰
        d: å·®åˆ†é˜¶æ•°ï¼Œ0 < d < 1
        window: æƒé‡æˆªæ–­çª—å£ï¼ˆé»˜è®¤ 100 å¤©ï¼‰
    
    è¿”å›:
        å·®åˆ†åçš„åºåˆ—ï¼ˆå‰ window-1 ä¸ªå€¼ä¸º NaNï¼‰
    
    ç®—æ³•:
        weights[0] = 1
        weights[k] = weights[k-1] * (d - k + 1) / k    (k = 1, 2, ..., window-1)
        fracdiff[t] = sum(weights[k] * series[t-k] for k in range(window))
    """

def find_optimal_d(
    series: pd.Series, 
    d_range: np.arange = np.arange(0.0, 1.05, 0.05),
    significance: float = 0.05
) -> float:
    """
    äºŒåˆ†æ³• / ç½‘æ ¼æœç´¢æ‰¾æœ€å° dï¼Œä½¿ ADF æ£€éªŒ p < significanceã€‚
    
    å…³é”®çº¦æŸ:
    - å¿…é¡»åªåœ¨ TRAIN é›†ä¸Šè¿è¡Œï¼ˆä¸èƒ½ç”¨ test æ•°æ®æ‹Ÿåˆ dï¼‰
    - è¿”å›æ»¡è¶³å¹³ç¨³æ€§çš„æœ€å° dï¼ˆä¿ç•™æœ€å¤§è®°å¿†ï¼‰
    
    è¿”å›:
        æœ€ä¼˜ d å€¼ï¼ˆå¦‚ 0.45ï¼‰
    """
```

### ä¸ç°æœ‰ç‰¹å¾å·¥ç¨‹çš„é›†æˆ

åœ¨ `src/features/build_features.py` ä¸­æ–°å¢ FracDiff ç‰¹å¾ï¼š

```python
# åœ¨ build_features() ä¸­ï¼Œå¯¹ adj_close æ–½åŠ  FracDiff
# d å€¼åœ¨ CPCV çš„æ¯ä¸ª fold å†…ç‹¬ç«‹æ‹Ÿåˆï¼ˆé˜²æ­¢ä¿¡æ¯æ³„æ¼ï¼‰
# 
# æ–°å¢ç‰¹å¾åˆ—:
#   fracdiff_close: FracDiff(adj_close, d=optimal_d)
#
# æ³¨æ„: d çš„æ‹Ÿåˆå±äº Phase C è®­ç»ƒå¾ªç¯çš„ä¸€éƒ¨åˆ†ï¼Œä¸æ˜¯ build_features çš„ä¸€éƒ¨åˆ†
# build_features åªè´Ÿè´£ã€Œç»™å®š d å€¼ï¼Œè®¡ç®— fracdiffã€
# d çš„æœç´¢åœ¨è®­ç»ƒè„šæœ¬ä¸­å®Œæˆ
```

### âš ï¸ Burn-in ä¸ CPCV æ–­å±‚çš„æ­£ç¡®è¡”æ¥ï¼ˆå®¡è®¡å®˜é¢„è­¦ï¼‰

è¿™æ˜¯ä¸€ä¸ªææ˜“è¸©çš„å·¥ç¨‹é™·é˜±ï¼š

**âŒ é”™è¯¯åšæ³•**ï¼šå…ˆ CPCV åˆ‡åˆ†å‡º Train é›† â†’ å†åœ¨ Train é›†ä¸Šç®— FracDiff

é—®é¢˜ï¼šCPCV çš„ Purge+Embargo ä¼šåœ¨æ—¶é—´è½´ä¸ŠæŒ–å‡ºç©ºæ´ï¼ˆä¸è¿ç»­ï¼‰ï¼Œæ¯ä¸ªæ–­å±‚éƒ½ä¼šå¯¼è‡´ FracDiff
å‰ `window`ï¼ˆé»˜è®¤ 100ï¼‰å¤©çš„æ•°æ®å˜æˆ NaNï¼Œå¤§é‡æœ‰æ•ˆè®­ç»ƒæ ·æœ¬è¢«ç™½ç™½çƒ§æ¯ã€‚

**âœ… æ­£ç¡®åšæ³•**ï¼šä¸¤æ­¥åˆ†ç¦»

ç¬¬ä¸€æ­¥ï¼šåœ¨å…¨é‡æ—¶é—´è½´ä¸Šé¢„è®¡ç®—æ‰€æœ‰å€™é€‰ d å€¼çš„ FracDiff åˆ—ã€‚
è¿™ä¸€æ­¥ä¸æ„æˆæ³„æ¼ï¼Œå› ä¸º FracDiff åªå‘å†å²å›çœ‹ï¼ˆçº¯å› æœè¿ç®—ï¼‰ã€‚

ç¬¬äºŒæ­¥ï¼šCPCV åˆ‡åˆ†åï¼ŒADF æ£€éªŒæ‰¾æœ€ä¼˜ d æ—¶åªçœ‹ Train çš„ indexã€‚

ç¬¬ä¸‰æ­¥ï¼šç”¨ optimal_d å¯¹åº”çš„é¢„è®¡ç®—åˆ—ä½œä¸ºè¯¥ fold çš„ç‰¹å¾ã€‚

**æ€»ç»“**ï¼šé¢„è®¡ç®—å…¨é‡ â‰  æ³„æ¼ï¼ˆå·®åˆ†åªçœ‹è¿‡å»ï¼‰ï¼Œæ‰¾ d åªçœ‹ Train = éš”ç¦»ã€‚

### ADF æ£€éªŒç”¨æ³•

```python
from statsmodels.tsa.stattools import adfuller

result = adfuller(fracdiff_series.dropna(), maxlag=1, regression='c')
p_value = result[1]
is_stationary = p_value < 0.05
```

### æµ‹è¯•æ ‡å‡†
```
tests/test_fracdiff.py:
  - test_d_zero_is_original: FracDiff(d=0) â‰ˆ åŸåºåˆ—
  - test_d_one_is_diff: FracDiff(d=1) â‰ˆ ä¸€é˜¶å·®åˆ†
  - test_optimal_d_stationary: æ‰¾åˆ°çš„ d ä½¿ ADF p < 0.05
  - test_memory_preserved: d < 1 æ—¶ï¼Œä¸åŸåºåˆ—çš„ç›¸å…³æ€§ > 0ï¼ˆè®°å¿†ä¿ç•™ï¼‰
  - test_no_future_leakage: FracDiff[t] åªä½¿ç”¨ t åŠä¹‹å‰çš„æ•°æ®
```

### äº¤ä»˜ç‰©
- `src/features/fracdiff.py`
- `tests/test_fracdiff.py`ï¼ˆ5+ ä¸ªæµ‹è¯•ï¼‰
- `pip install statsmodels --break-system-packages`ï¼ˆADF æ£€éªŒä¾èµ–ï¼‰

---

## Step 4: Meta-MVP é—­ç¯

### ç›®æ ‡
å°†å‰ 3 æ­¥çš„æ‰€æœ‰ç»„ä»¶ä¸²è”æˆå®Œæ•´çš„è®­ç»ƒ-éªŒè¯-è¾“å‡ºç®¡é“ã€‚

### æ–°å»ºæ–‡ä»¶

**`src/models/meta_trainer.py`**

```
æ ¸å¿ƒæµç¨‹:

class MetaTrainer:
    """
    Meta-Labeling è®­ç»ƒç®¡é“ã€‚
    
    å®Œæ•´æµç¨‹:
    1. åŠ è½½ Phase A-B äº§å‡ºçš„ç‰¹å¾+æ ‡ç­¾æ•°æ®
    2. Base Model ç”Ÿæˆæ–¹å‘ä¿¡å· side
    3. è¿‡æ»¤: åªä¿ç•™ side != 0 çš„æ ·æœ¬
    4. æ ‡ç­¾è½¬æ¢: {profit â†’ 1, loss â†’ 0}ï¼ˆMeta-Label: ä¿¡å·æ˜¯å¦ç›ˆåˆ©ï¼‰
    5. å¯¹æ¯ä¸ª CPCV fold:
       a. åœ¨ train é›†ä¸Šç”¨äºŒåˆ†æ³•æ‰¾æœ€ä¼˜ FracDiff d
       b. ç”¨è¯¥ d å€¼è®¡ç®— train å’Œ test çš„ FracDiff ç‰¹å¾
       c. è®­ç»ƒ LightGBM (ä» training.yaml è¯»å‚æ•°)
       d. åœ¨ test é›†ä¸Šé¢„æµ‹æ¦‚ç‡ p
    6. æ±‡æ€» 15 æ¡ path çš„ç»“æœ
    7. è¾“å‡º: æ¦‚ç‡æ ¡å‡†æ›²çº¿ã€AUCã€PBO ä¼°è®¡
    """
    
    def train(self, df: pd.DataFrame) -> Dict:
        """
        è¿”å›:
        {
            'paths': [...],          # 15 æ¡ path çš„ AUC / Accuracy
            'mean_auc': float,       # å¹³å‡ AUC
            'pbo': float,            # Probability of Backtest Overfitting
            'feature_importance': {}, # SHAP æˆ– MDA
            'dummy_sentinel': {      # å“¨å…µæ£€æŸ¥
                'dummy_rank': int,
                'passed': bool
            }
        }
        """
```

### LightGBM è°ƒç”¨æ–¹å¼

```python
import lightgbm as lgb
import yaml

with open('config/training.yaml') as f:
    cfg = yaml.safe_load(f)

lgb_params = cfg['lightgbm'].copy()

# âš ï¸ OR5-CODE T5: è¿™äº›å‚æ•°å¿…é¡»ä» params dict ä¸­ .pop() å‡ºæ¥
# å› ä¸ºå®ƒä»¬æ˜¯ lgb.train() çš„å‚æ•°ï¼Œä¸æ˜¯ LightGBM æ¨¡å‹å‚æ•°
# ç›´æ¥ä¼ å…¥ä¼šè§¦å‘ LightGBM "unknown parameter" warning
n_estimators = lgb_params.pop('n_estimators', 500)
early_stopping_rounds = lgb_params.pop('early_stopping_rounds', 50)

# lgb_params ç°åœ¨åªåŒ…å«æ¨¡å‹è¶…å‚ï¼ˆmax_depth, num_leaves, ç­‰ï¼‰
# è¿™äº›æ˜¯ OR5 ç¡¬åŒ–çš„å‚æ•°ï¼Œä¸¥ç¦ä¿®æ”¹

train_data = lgb.Dataset(
    X_train, 
    label=y_train,           # Meta-Label: 1=ä¿¡å·ç›ˆåˆ©, 0=ä¿¡å·äºæŸ
    weight=w_train            # AFML uniqueness æƒé‡ï¼ˆå·²åœ¨ Phase B è®¡ç®—å¥½ï¼‰
)

model = lgb.train(
    lgb_params,
    train_data,
    num_boost_round=n_estimators,  # ä½¿ç”¨ .pop() å‡ºæ¥çš„å€¼
    valid_sets=[valid_data],
    callbacks=[lgb.early_stopping(early_stopping_rounds)]  # ä½¿ç”¨ .pop() å‡ºæ¥çš„å€¼
)

# è¾“å‡ºæ¦‚ç‡
proba = model.predict(X_test)  # P(base signal is profitable)
```

### å“¨å…µæ£€æŸ¥ï¼ˆå¿…é¡»é€šè¿‡æ‰ç®—æœ‰æ•ˆï¼‰

```python
# 1. Dummy Feature Sentinel
# dummy_noise åœ¨ Phase A å·²æ³¨å…¥ç‰¹å¾ï¼Œå¦‚æœå®ƒæ’åè¿›å…¥ top 25%ï¼Œè¯´æ˜è¿‡æ‹Ÿåˆ
importance = model.feature_importance(importance_type='gain')
dummy_rank = ...  # dummy_noise çš„æ’å
assert dummy_rank > len(features) * 0.25, "Overfitting detected!"

# 2. PBO (Probability of Backtest Overfitting)
# plan.md ä¸‰æ¡£é—¨æ§:
#   PBO < 0.3 â†’ Passï¼ˆè¿›å…¥ Phase C+ æˆ– Phase Dï¼‰
#   0.3 â‰¤ PBO < 0.5 â†’ Warningï¼ˆå…è®¸ç»§ç»­ä½†å¿…é¡»äººå·¥å¤æ ¸ï¼ŒæŠ¥å‘Šä¸­æ ‡çº¢ï¼‰
#   PBO â‰¥ 0.5 â†’ Hard Rejectï¼ˆå›é€€ Phase B è°ƒæ•´ç‰¹å¾/æ ‡ç­¾ï¼‰
pbo = calculate_pbo(path_results)
if pbo >= 0.5:
    raise ValueError(f"HARD REJECT: PBO={pbo:.2f} >= 0.5, model rejected!")
elif pbo >= 0.3:
    logger.warning(f"PBO WARNING: PBO={pbo:.2f} in [0.3, 0.5) â€” requires manual review")
    report['pbo_warning'] = True  # æŠ¥å‘Šä¸­å¿…é¡»æ ‡çº¢
    # ä¸é˜»æ–­ï¼Œä½†å¿…é¡»äººå·¥å¤æ ¸
```

### å›æµ‹æŠ¥å‘Šæ‰£å‡ï¼ˆç¡¬ç¼–ç ï¼‰

```python
# æœ€ç»ˆè¾“å‡ºæŠ¥å‘Šæ—¶:
SURVIVORSHIP_CAGR_PENALTY = 0.02
LOOKAHEAD_CAGR_PENALTY = 0.01
MDD_INFLATION = 0.10

report['adjusted_cagr'] = report['raw_cagr'] - SURVIVORSHIP_CAGR_PENALTY - LOOKAHEAD_CAGR_PENALTY
report['adjusted_mdd'] = report['raw_mdd'] + MDD_INFLATION
# å±•ç¤ºæ—¶å¿…é¡»ç”¨ adjusted å€¼
```

### æµ‹è¯•æ ‡å‡†
```
tests/test_meta_trainer.py:
  - test_full_pipeline_runs: åˆæˆæ•°æ®è·‘é€šå®Œæ•´æµç¨‹
  - test_meta_label_binary: æ ‡ç­¾åªæœ‰ 0 å’Œ 1
  - test_sample_weight_passed: LGB æ¥æ”¶åˆ° sample_weight
  - test_dummy_sentinel_catches_overfit: äººé€ è¿‡æ‹Ÿåˆåœºæ™¯è§¦å‘å“¨å…µ
  - test_cpcv_15_paths: ç¡®è®¤äº§å‡º 15 æ¡ path
  - test_lgb_params_from_config: å‚æ•°ä» YAML è¯»å–ï¼Œä¸æ˜¯ç¡¬ç¼–ç 
```

### äº¤ä»˜ç‰©
- `src/models/meta_trainer.py`
- `tests/test_meta_trainer.py`ï¼ˆ6+ ä¸ªæµ‹è¯•ï¼‰
- å…¨é‡æµ‹è¯•é€šè¿‡

---

## æ–‡ä»¶ç»“æ„æ€»è§ˆï¼ˆPhase C å®Œæˆåï¼‰

```
src/
â”œâ”€â”€ signals/
â”‚   â””â”€â”€ base_models.py          # Step 1: SMA Cross + Momentum
â”œâ”€â”€ features/
â”‚   â”œâ”€â”€ build_features.py       # å·²æœ‰ï¼ŒPhase A
â”‚   â””â”€â”€ fracdiff.py             # Step 3: åˆ†æ•°é˜¶å·®åˆ†
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ purged_kfold.py         # Step 2: CPCV æ‰‹å†™éš”ç¦»å™¨
â”‚   â””â”€â”€ meta_trainer.py         # Step 4: Meta-Labeling è®­ç»ƒç®¡é“
â”œâ”€â”€ labels/
â”‚   â”œâ”€â”€ triple_barrier.py       # å·²æœ‰ï¼ŒPhase B (å« OR5 hotfix)
â”‚   â””â”€â”€ sample_weights.py       # å·²æœ‰ï¼ŒPhase B
tests/
â”œâ”€â”€ test_base_models.py         # Step 1 æµ‹è¯•
â”œâ”€â”€ test_cpcv.py                # Step 2 æµ‹è¯•
â”œâ”€â”€ test_fracdiff.py            # Step 3 æµ‹è¯•
â””â”€â”€ test_meta_trainer.py        # Step 4 æµ‹è¯•
```

---

## é‡Œç¨‹ç¢‘æ£€æŸ¥ç‚¹

| æ£€æŸ¥ç‚¹ | å®Œæˆæ ‡å¿— | é˜»æ–­æ¡ä»¶ |
|--------|---------|---------|
| Step 1 å®Œæˆ | base_model â†’ triple_barrier è·‘é€šï¼Œside æ— å‰è§† | side ç”¨äº† T æ—¥ä»·æ ¼ |
| Step 2 å®Œæˆ | 15 æ¡ CPCV pathï¼Œå…¨éƒ¨ â‰¥ 200 å¤©è®­ç»ƒæ•°æ® | train/test æœ‰æ—¶é—´äº¤é›† |
| Step 3 å®Œæˆ | ADF p < 0.05 ä¸”ä¸åŸåºåˆ—ç›¸å…³æ€§ > 0 | d åœ¨ test é›†ä¸Šæ‹Ÿåˆ |
| Step 4 å®Œæˆ | 15 path AUC æ±‡æ€» + PBO < 0.3 (Pass) æˆ– 0.3-0.5 (Warning+äººå·¥å¤æ ¸) + å“¨å…µé€šè¿‡ | PBO â‰¥ 0.5 |

**æ¯ä¸ª Step å®Œæˆåéƒ½è¦è·‘å…¨é‡æµ‹è¯•ç¡®è®¤ä¸å›å½’ï¼Œç„¶åå•ç‹¬ commit + pushã€‚**

---

## å¦‚æœé‡åˆ°é—®é¢˜

| é—®é¢˜ | å¯¹ç­– |
|------|------|
| FracDiff å ADF ä»ä¸å¹³ç¨³ | å¢å¤§ d å€¼æˆ–å¢å¤§çª—å£ window |
| CPCV purge åè®­ç»ƒæ•°æ®å¤ªå°‘ | æ£€æŸ¥ embargo_window æ˜¯å¦è¿‡å¤§ï¼Œæˆ–æ•°æ®æ€»é‡ä¸è¶³ |
| LightGBM AUC â‰ˆ 0.50 | æ­£å¸¸ã€‚æ—¥é¢‘ç¾è‚¡ä¿¡å™ªæ¯”æä½ï¼Œ0.52 å°±å€¼å¾—è®¤çœŸå¯¹å¾… |
| PBO â‰¥ 0.3 | æ¨¡å‹è¿‡æ‹Ÿåˆè­¦å‘Šã€‚è‹¥ PBO < 0.5ï¼šæ£€æŸ¥ç‰¹å¾è´¨é‡ã€è€ƒè™‘å¢åŠ æ­£åˆ™åŒ–ï¼ˆå‡ num_leavesã€å¢ min_data_in_leafï¼‰ï¼›è‹¥ PBO â‰¥ 0.5ï¼šå¿…é¡»å›é€€ Phase B é‡æ–°è°ƒæ•´ |
| dummy_noise è¿›å…¥ top 25% | è¿‡æ‹Ÿåˆç¡®è®¤ï¼Œæ‹’ç»å½“å‰æ¨¡å‹ï¼Œå›æŸ¥ç‰¹å¾ |
